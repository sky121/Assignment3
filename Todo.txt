Milestone 3

TO DO:
- 20 queries
- README
- Heuristic: Only consider high idf query terms and docs containing many query terms
- Improve performance of observations

observations
1. queries that have more unique words take more time
2. queries with repeated words do not take anymore time (e.g. cristina lopes vs cristina lopes cristina lopes cristina lopes)
3. queries with few unique words take less time
4. common words take longer (e.g. to be vs cristina lopes)

Imrpovements to be made:
1. consider only the higher idf score terms when the idf score of the words in the query are quite different
2. consider only the part of the query terms 
3. Set a minimum thresold for the idf score as a mean to cut of the useless doc in the posting list
4. Terminate early by setting K. (combination of previous 4 methods might work pretty well)
5. Build separate index for fields such as author, title, year. (I have no idea how to do so, bs4 parser?)
6. build index for zones such as the title, abstract, body paragraphs, references.
7. If we build different indexes, we can rank the indexes into tiers. We can only use the higher tier indexes such as the author index.
8. build index with word position. If two words from query appear close in a doc , we give the doc a higher weight. 
9. Maybe we can add the authority ranking (I dont think its necessary since we only consider ics domain)

doc_vector_length.txt
docid1:sqrt_sum_of_square_tf
docid2:sqrt_sum_of_square_tf




- Delay time (0.03 -> 30 ms)
TO DO FOR US:
Getting vector of query:
  1. get the tf raw of the query (count frequency of each term)
  2. get the tf weight from the first tf (1+log(tf-raw)) 
  3. df = document frequency for each term
  4. follow the formula to get the idf = log10(N/df)
  5. get the weight. Weight = tf * idf
  6. divide weight to be normalized unit vectors = wt/sqrt(sum of squares of weights)


  Getting vector of docs:
  1. tf raw for doc(number of time that term appears in the doc)
  2. get the tf weight from the first tf (1+log(tf-raw)) 
  3. divide weight to be normalized unit vectors = wt/sqrt(sum of squares of weights)


  score = product of normalized vector doc with normalized vector query 

  fix the operating system issue

  MIGHT NEED TO SUBTRACT 1 FOR EXTRA LINE AT THE END OF DOC VECTOR LENGTH TXT



-Come up with a set of at least 20 queries
  -in terms of ranking performance (effectiveness) and in terms of runtime performance (efficiency)
  -At least half of those queries should be chosen because they do poorly on one or both criteria; the other half should do well 
  -as general as possible.



Deliverables:
-Setup README explaining how to use your programs
-PDF document with your test queries(no need to report the results)
  -which ones started by doing poorly (i.e. giving you poor results) and explain what you did in your search engine to make them perform better.

Does your search engine work as expected of search engines?
• How general are the heuristics that you employed to improve the retrieval?
• Is the search response time under the expected limit?
• Do you demonstrate in-depth knowledge of how your search engine works? Are you able to answer detailed questions pertaining to any aspect of its implementation?





Milestone 2

At least the following queries should be used to test your retrieval:
keyword:
  1 – cristina lopes
  2 - machine learning
  3 - ACM
  4 - master of software engineering
the top 5 URLs for each of the queries above
support boolean AND


TODO:
when we merge the document lists, we have to add tf_idf scores (DONE)
speed up the merging by putting list1 into a map and just interate through list2 and check the map for each of the values(DONE)
doc id to url






Milestone 1

Inverted Index:
  tokens->postings(doc_id, tf-idf(token frequency))

Deliverables: Submit your code and a report (in PDF format) with a table containing some analytics about your index. The minimum analytics are:  
  -The number of indexed documents;
  -The number of unique words;
  -The total size (in KB) of your index on disk.

Index.json:
{
  "token1":{
    "num_docs":0,
    "doc_id1":{
      "tf_idf": 0
    },
  "token2":{
    "num_docs":0,
    "doc_id1":{
      "tf_idf": 0
    },
  },
}

index.txt

token1:num_docs,doc_id1:tf_idf,doc_id2:tf_idf,doc_id3:tf_idf
token2:num_docs,doc_id1:tf_idf,doc_id2:tf_idf
token3:num_docs,doc_id1:tf_idf


Note:
  - Tokens: all alphanumeric sequences in the data
  - Stop words: do not use stopping while indexing, i.e. use all words, even the frequently occurring ones.
  - Stemming: use stemming for better textual matches. Suggestion: Porter stemming, but it is up to you to choose.
  - Important text: text in bold (b, strong), in headings (h1, h2, h3), and in titles should be treated as more important than the in other places.Verify which are the relevant HTML tags to select the important words
  - Your index should be stored in one or more fles in the program file system (no databases!)
  - The response to search queries should be 300ms or less  
  = Your indexer must off load the inverted index hash map from main memory to a partial index on disk at least 3 times during index construction;
    those partial indexes should be merged in the end.Optionally, after or during merging, they can also be split into separate indexfiles  with  term  ranges.
    Similarly,  your  search  component  must  not  load  theentire inverted index in main memory.



Extra Credit
Extra credit will be given for tasks that improve the retrieval and the user search experience - except for GUI, you must code from scratch. For Example:
• Detect and eliminate duplicate pages. (1 point for exact, 2 points for near)
• Add HITS and Page Rank to ranking. (1.5 point HITS, 2.5 for PR)
• Implement 2-gram and/or 3-gram indexing and use it during retrieval. (1point)
• Enhance the index with word positions and use that information for retrieval. (2 points)
• Index anchor words for the target pages (1 point).
• Implement a Web or GUI interface instead of using the console. (1 pointfor the local GUI, 2 points for a web GUI)